{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "[01. Import Library](#01)<br>\n",
    "[02. Load Data](#02)<br>\n",
    "[03. Exploratory Data Analysis (EDA)](#03)<br>\n",
    "&nbsp;&nbsp;&nbsp;[3.1. Dependent Variable](#3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Import Library<a id='01'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "\n",
    "import pandas_profiling\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Load Data <a id='02'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "print(\"List of files:\", os.listdir('/kaggle/input/house-prices-advanced-regression-techniques'))\n",
    "\n",
    "# Train data\n",
    "df_train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "print(\"\\nTrain data length:\",df_train.shape)\n",
    "print(\"\\nTrain data columns:\",df_train.columns)\n",
    "print(\"\\nTrain data columns:\",df_train.info())\n",
    "print(\"\\nTrain data:\\n\\n\",df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n",
    "print(\"\\nTest data length:\",df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Exploratory Data Analysis (EDA)<a id='03'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "df_train_corr = df_train.corr()\n",
    "df_train_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_corr.style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice has highest corr with OverallQual\n",
    "df_train_corr[['SalePrice','OverallQual']].style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use panda profile report\n",
    "# df_train.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Dependent Variable<a id='3.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=df_train['SalePrice'].plot.hist(bins=100, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matplotlib\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "plt.hist(df_train['SalePrice'], bins = 100)\n",
    "\n",
    "# Add title and axis names\n",
    "plt.title('Sales Price')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Price') \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_train['GrLivArea'], df_train['SalePrice'])\n",
    "plt.ylabel('SalePrice', fontsize=12)\n",
    "plt.xlabel('GrLivArea', fontsize=12)\n",
    "plt.title('Sale Price', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ-plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "res = stats.probplot(df_train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use plotly_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot with color from 2nd variable\n",
    "px.scatter(df_train, x='GrLivArea', y='SalePrice', color='OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot with color from 2nd variable\n",
    "px.scatter(df_train, x='TotalBsmtSF', y='SalePrice', color='OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "px.box(df_train[['OverallQual', 'SalePrice']].sort_values(by='OverallQual')\n",
    "       , x='OverallQual'\n",
    "       , y='SalePrice'\n",
    "       , color='OverallQual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "px.box(df_train[['SaleCondition', 'SalePrice']].sort_values(by='SaleCondition')\n",
    "       , x='SaleCondition'\n",
    "       , y='SalePrice'\n",
    "       , color='SaleCondition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot\n",
    "px.box(df_train[['ExterQual', 'SalePrice']].sort_values(by='ExterQual')\n",
    "       , x='ExterQual'\n",
    "       , y='SalePrice'\n",
    "       , color='ExterQual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['SalePrice'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(df_train['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "# Plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='upper right')\n",
    "\n",
    "ax = plt.axes()\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train_corr, \n",
    "            xticklabels=df_train_corr.columns.values,\n",
    "            yticklabels=df_train_corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['SalePrice'], axis = 1).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean outliers\n",
    "print(\"Length of data before dropping outliers:\", len(df_train))\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>4000) \n",
    "                                & (df_train['SalePrice']<300000)].index)\n",
    "print(\"Length of data after dropping outliers:\", len(df_train))\n",
    "df_train = df_train.drop(df_train[(df_train['GrLivArea']>5000) \n",
    "                                | (df_train['SalePrice']>500000)].index)\n",
    "print(\"Length of data after dropping outliers:\", len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Variables\n",
    "quan_var = [q for q in df_train.columns if df_train.dtypes[q] != 'object']\n",
    "quan_var.remove('SalePrice') \n",
    "quan_var.remove('Id')\n",
    "print(\"Quantitative Variables:\\n\", quan_var)\n",
    "\n",
    "# Qualitative Variables\n",
    "qual_var = [q for q in df_train.columns if df_train.dtypes[q] == 'object']\n",
    "print(\"\\nQualitative Variables:\\n\", qual_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "y_train = df_train.SalePrice.values\n",
    "df_all_data = pd.concat((df_train, df_test)).reset_index(drop=True)\n",
    "df_all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(df_all_data.shape))\n",
    "\n",
    "# Calculate missing data ratio\n",
    "df_all_data_na = (df_all_data.isnull().sum() / len(df_all_data)) * 100\n",
    "df_all_data_na = df_all_data_na.drop(df_all_data_na[df_all_data_na == 0].index).sort_values(ascending=False)[:50]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :df_all_data_na})\n",
    "print('Missing data percentage:\\n',missing_data.head(50))\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "ax.set_facecolor(\"white\")\n",
    "sns.barplot(x=df_all_data_na.index, y=df_all_data_na)\n",
    "sns.color_palette('pastel')\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Percent of missing values', fontsize=12)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=['Model','RMSE','MSE','Summary'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Linear Regression on a single variable that has the highest corr with dependent variable\n",
    "X = df_train[['OverallQual']]\n",
    "y = df_train['SalePrice']\n",
    "\n",
    "# Train Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Linear Regression Model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "df_result = df_result.append(pd.DataFrame([['Linear Regression'\n",
    "                                            , rmse\n",
    "                                            , mse\n",
    "                                            ,'Baseline model'                               \n",
    "                                           ]], columns=df_result.columns))\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=10)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "df_result = df_result.append(pd.DataFrame([['RandomForestRegressor'\n",
    "                                            , rmse\n",
    "                                            , mse\n",
    "                                            ,'Baseline model'                               \n",
    "                                           ]], columns=df_result.columns))\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features - Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of variable based on missing data ratio\n",
    "features_for_reg = missing_data[missing_data['Missing Ratio']<50].index.values.tolist()\n",
    "\n",
    "\n",
    "# Get Dummies\n",
    "X_all = pd.get_dummies(df_all_data[features_for_reg])\n",
    "X_all.fillna(0, inplace=True)\n",
    "\n",
    "X = X_all[0:len(df_train)]\n",
    "y = df_train['SalePrice']\n",
    "\n",
    "# Initiate train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=3)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "df_result = df_result.append(pd.DataFrame([['RandomForestRegressor'\n",
    "                                            , rmse\n",
    "                                            , mse\n",
    "                                            ,'Features with less than 50% missing data'                               \n",
    "                                           ]], columns=df_result.columns))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = rf.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X_train.columns[i] for i in indices]\n",
    "\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features - Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of variable based on rf feature importance\n",
    "features_for_reg = names[:45]\n",
    "\n",
    "\n",
    "# Run Linear Regression\n",
    "X_all = X_all[features_for_reg]\n",
    "X_all.fillna(0, inplace=True)\n",
    "\n",
    "X = X_all[0:len(df_train)]\n",
    "y = df_train['SalePrice']\n",
    "\n",
    "# Initiate train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=3)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "df_result = df_result.append(pd.DataFrame([['RandomForestRegressor'\n",
    "                                            , rmse\n",
    "                                            , mse\n",
    "                                            ,'Important features based on RF'                               \n",
    "                                           ]], columns=df_result.columns))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = rf.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X_train.columns[i] for i in indices]\n",
    "\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New feature\n",
    "df_all_data[\"OverallQual_Garage_GrLivArea\"] = df_all_data[\"OverallQual\"] * df_all_data[\"GarageArea\"] * df_all_data[\"GrLivArea\"]\n",
    "\n",
    "# Get Dummies\n",
    "X_all = pd.get_dummies(df_all_data)\n",
    "X_all.fillna(0, inplace=True)\n",
    "\n",
    "X = X_all[0:len(df_train)]\n",
    "y = df_train['SalePrice']\n",
    "\n",
    "# Initiate train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=3)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"Root Mean Squared Error: {:.2f}\".format(rmse))\n",
    "df_result = df_result.append(pd.DataFrame([['RandomForestRegressor'\n",
    "                                            , rmse\n",
    "                                            , mse\n",
    "                                            ,'Features engineering'                               \n",
    "                                           ]], columns=df_result.columns))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = rf.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X_train.columns[i] for i in indices]\n",
    "\n",
    "print(len(names))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "X_test = X_all.iloc[len(df_train):len(X_all)]\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "sub = pd.DataFrame()\n",
    "sub['Id'] = df_test['Id']\n",
    "sub['SalePrice'] = y_pred_rf\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
